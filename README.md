# ğŸ“ Progetto ARTES 4.0 - NOMADIA

## ğŸ§  Descrizione del Progetto

**NOMADIA** Ã¨ un progetto sviluppato con lâ€™obiettivo di realizzare un sistema intelligente, mobile e low-cost per il monitoraggio dello stato di usura delle pavimentazioni stradali.

Il sistema Ã¨ basato su:
- Sensori MEMS (Micro-Electro-Mechanical Systems)
- Videocamere
- Reti neurali e tecniche di **Intelligenza Artificiale (AI)**

Lâ€™obiettivo Ã¨ **riconoscere automaticamente ammaloramenti dellâ€™asfalto** (fessurazioni, buche, deterioramenti) attraverso un'analisi integrata dei dati acustici e visivi raccolti durante il normale transito di veicoli.

## ğŸ¯ Obiettivi Principali

- **Monitoraggio continuo e automatizzato** delle condizioni stradali.
- **Riduzione dei costi e dei disagi** legati agli interventi manutentivi non necessari.
- **Aumento della sicurezza stradale** e riduzione dellâ€™esposizione al rumore.
- **Ottimizzazione delle risorse pubbliche** e supporto alla pianificazione preventiva.
- Migliore **sostenibilitÃ  ambientale ed economica**.

## ğŸ› ï¸ Funzionamento del Sistema

1. Il sistema viene installato su un veicolo (es. mezzo comunale, bus, veicolo di servizio).
2. Durante la marcia, vengono registrati:
   - **Dati acustici** allâ€™interno del pneumatico (tramite microfoni MEMS),
   - **Video della pavimentazione** stradale.
3. I dati vengono elaborati in locale tramite modelli AI.
4. Gli ammaloramenti vengono **identificati, classificati e georeferenziati**.
5. Si genera cosÃ¬ un indice che descrive lo stado di deterioramento dei vari tratti di strada analizzati.
6. I risultati sono mostrati su una mappa come quella in figura qui sotto in cui a ciascun colore corrisponde un indice del degrado stradale.
<img src="results/output_map.png" alt="Logo" /> 


## âš™ï¸ Tecnologie Utilizzate

- **Sensoristica integrata** (microfoni MEMS, videocamere)
- **AI & Machine Learning**:
  - Reti neurali convoluzionali per lâ€™analisi visiva
  - Modelli acustici per la classificazione dei danni
- **Elaborazione dati** su edge e cloud
- **Georeferenziazione** dei dati raccolti (sistemi GIS)
- **Piattaforma di visualizzazione** e reporting per i gestori dellâ€™infrastruttura

## ğŸ—ƒï¸ Struttura del Progetto

La struttura del progetto Ã¨ la seguente:
ARTES.4.0-NOMADIA/

â”œâ”€â”€ README.md        # Descrizione generale del progetto

â”œâ”€â”€ docs/                    # Documentazione tecnica e manuali 

â”œâ”€â”€ results/                 # Esempio di risultati 

â”œâ”€â”€ data/                    # Esempio dati acquisiti (per categoria) 

â”‚   â”œâ”€â”€ gps                   # esempio dati gps raccolti (per intervalli 20m) 

â”‚   â”œâ”€â”€ tcn                   # esempio dati audio raccolti (interpolati) 

â”‚   â”œâ”€â”€ video.txt             # link video esempio 

â”œâ”€â”€ src/                     # Codice sorgente (modelli AI, algoritmi di analisi)

â”‚   â”œâ”€â”€ audio               # Raccolta dati e analisi acustica 

â”‚   â”œâ”€â”€ video               # Elaborazione video e riconoscimento visivo


## ğŸ“‹ Requisiti Tecnici

Le dipendenze principali sono contenute rispettivamente nei file requirements.txt di ciascuna cartella (audio e video).

Le dipendenze principali risultano essere:
  - **Python 3.9+**
  - `TensorFlow` o `PyTorch`
  - `OpenCV`
  - `NumPy`, `Pandas`
  - `scikit-learn`
  - `matplotlib`, `seaborn`
  - `geopandas` (per la mappatura georeferenziata)
- Sistema con supporto per:
  - Microfoni MEMS (inserito su modulo ESP32)
  - Videocamera
  - GPS

NOTA: si consiglia di utilizzare due ambienti virtuali una per la parte audio ed una per la parte video

Ad esempio per creare l'ambiente audio, utilizzare il seguente comando:

```bash
python -m venv nome_ambiente_audio
```
per attivarlo digitare:
```bash
source nome_ambiente_audio/bin/activate
```
successivamente, installare i requisiti necessari
```bash
pip install -r requirements_audio.txt
```
una volta creato, per disattivarlo, digitare:
```bash
deactivate
```
Ripetere gli step di creazione, attivazione e installazione anche per la parte video

## ğŸ“‹ Esecuzione misura
Come prima cosa attivare l'apposito ambiente virtuale appena creato
```bash
source nome_ambiente_audio/bin/activate
```

DopodichÃ© verificare che tutti gli strumenti siano connessi con la scheda di elaborazione ed
eseguire il codice di raccolta dati con il comando:
```bash
python src/audio/main.py
```
Per interrompere la misura basta premere il tasto "ENTER".  

Al termine il risultato dell'acquisizione sarÃ  salvato all'interno di apposite cartelle, per i dati audio (interpolati) e per i dati gps (suddivisi in intervalli da 20m). 

Per quanto riguarda il video acquisito della GoPro, si puÃ² scegliere la metodologia preferita per scaricarlo (wifi, cavo, sd). Si consiglia il salvataggio in una cartella di facile accesso (es: data).

## ğŸ“‹ Elaborazione misura
Al fine di analizzare coerentemente i dati raccolti e preprocessati durante la fase di misura Ã¨ necessario procedere per step: iniziando con l'analisi della componente acustica (al fine di produrre una prima classificazione), per poi concludere con la parte visiva per ottenere l'indice finale su ciascun tratto.

### PARTE AUDIO
Per effettuare l'analisi audio Ã¨ prima necessario disattivare l'ambiente virtuale mediante il comando
```bash
deactivate
```
Ã¨ poi sufficiente eseguire il codice:
```bash
python src/audio/Classificazione_tcn.py
```
assicurandosi di scegliere il fit piÃ¹ adatto alla misura in analisi (urbana, extraurbana o autostradale) decommentando la riga appropriata (37-39).

### PARTE VIDEO
Sia **path_video** il percorso alla cartella contenente il/i video registrati durante l'esecuzione della misura; e **path_indice_audio** il percorso al file csv risultante dall'analisi audio appena svolta.

Per eseguire l'analisi video Ã¨ sufficiente indicare tali percorsi all'interno del file **src/video/main.py** (rispettivamente righe 9 e 22) e lanciare il codice:
```bash
python src/video/main.py
```

## ğŸ“‹ Output Previsti
Il risultato verrÃ  salvato nella cartella di lavoro sottoforma di:

- Segmentazione visiva dei danni (immagini e labels derivanti dall'esecuzione del modello) 
- Mappa georeferenziata degli intervalli (20m) analizzati (formato html)
- Classificazione dello stato della pavimentazione in base ad un indice audio-video personalizzato (file csv)
